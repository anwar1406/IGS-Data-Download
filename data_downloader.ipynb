{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoXZZapEV0yeCWPzDj/R8N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This module provides utilities to  download IGS station data files\n",
        "(e.g., observation and navigation files) from the specified FTP server"
      ],
      "metadata": {
        "id": "QFpPwAZuevfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import modules\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "from datetime import datetime, timedelta\n",
        "from contextlib import closing\n",
        "from urllib.request import URLError"
      ],
      "metadata": {
        "id": "8XvNkBunSGyb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = [\"gps_week\", \"igs_station_data\",\"download_igs_product\"]\n",
        "\n",
        "def gps_week(day_of_year, year):\n",
        "    \"\"\"\n",
        "    Convert day of year and year to GPS week.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    day_of_year : int\n",
        "        Day of the year (1-365 or 1-366 for leap years).\n",
        "    year : int\n",
        "        The year (e.g., 2023).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "        The corresponding GPS week number.\n",
        "    \"\"\"\n",
        "    gps_epoch = datetime(1980, 1, 6)\n",
        "\n",
        "    # Convert year and day of year to a date\n",
        "    target_date = datetime(year, 1, 1) + timedelta(days=day_of_year - 1)\n",
        "\n",
        "    # Calculate difference in days from GPS epoch\n",
        "    days_since_epoch = (target_date - gps_epoch).days\n",
        "\n",
        "    # Calculate GPS week\n",
        "    return days_since_epoch // 7\n",
        "\n",
        "def igs_station_data(station_name, doy_i, doy_f, year, country_name=\"IND\", save_path=\"\"):\n",
        "    \"\"\"\n",
        "    Download IGS station data (observation and navigation files) for a given station and date range.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    station_name : str\n",
        "        Name of the GNSS station (e.g., \"IISC\").\n",
        "    doy_i : int\n",
        "        Start day of the year (DOY).\n",
        "    doy_f : int\n",
        "        End day of the year (DOY).\n",
        "    year : int\n",
        "        The year of the data (e.g., 2023).\n",
        "    country_name : str, optional\n",
        "        Country code (e.g., \"IND\" for India). Default is \"IND\".\n",
        "    save_path : str, optional\n",
        "        Directory to save the downloaded files. Default is the current directory.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        Downloads the files to the specified directory.\n",
        "    \"\"\"\n",
        "    base_url = r\"ftp://gssc.esa.int/gnss/data/daily/\"\n",
        "\n",
        "    for i in range(doy_i, doy_f + 1):  # Include `doy_f`\n",
        "        day_of_year = f\"{i:03}\"  # Zero-padded day of year\n",
        "        path = f\"{base_url}{year}/{day_of_year}/\"\n",
        "\n",
        "        # File names\n",
        "        file_MO = f\"{station_name}00{country_name}_R_{year}{day_of_year}0000_01D_30S_MO.crx.sum.gz\"\n",
        "        file_MN = f\"{station_name}00{country_name}_R_{year}{day_of_year}0000_01D_MN.rnx.gz\"\n",
        "\n",
        "        # Download observation file\n",
        "        try:\n",
        "            with closing(urllib.request.urlopen(path + file_MO)) as r:\n",
        "                save_path1 = os.path.join(save_path, file_MO) if save_path else file_MO\n",
        "                with open(save_path1, 'wb') as f:\n",
        "                    shutil.copyfileobj(r, f)\n",
        "                    print(f\"Observation file for DOY {i} has been downloaded\")\n",
        "        except URLError:\n",
        "            print(f\"Observation file for DOY {i} is missing\")\n",
        "\n",
        "        # Download navigation file\n",
        "        try:\n",
        "            with closing(urllib.request.urlopen(path + file_MN)) as r:\n",
        "                save_path1 = os.path.join(save_path, file_MN) if save_path else file_MN\n",
        "                with open(save_path1, 'wb') as f:\n",
        "                    shutil.copyfileobj(r, f)\n",
        "                    print(f\"Navigation file for DOY {i} has been downloaded\")\n",
        "        except URLError:\n",
        "            print(f\"Navigation file for DOY {i} is missing\")\n",
        "\n",
        "\n",
        "def download_igs_product(year, doy_i, doy_f, product_name, save_path=\"\"):\n",
        "    \"\"\"\n",
        "    Downloads a specified IGS rapid product (SP3, CLK, ERP) for a range of days in a given year.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    year : int\n",
        "        Year for which the data is downloaded.\n",
        "    doy_i : int\n",
        "        Starting day of the year (1-365/366).\n",
        "    doy_f : int\n",
        "        Ending day of the year (1-365/366).\n",
        "    product_name : str\n",
        "        Name of the product to download (\"SP3\", \"CLK\", or \"ERP\").\n",
        "    save_dir : str, optional\n",
        "        Directory where the downloaded files will be saved. Default is \"IGS_Products\".\n",
        "    path : str, optional\n",
        "        Base FTP path to IGS products. Default is \"ftp://gssc.esa.int/gnss/products/\".\n",
        "    \"\"\"\n",
        "\n",
        "    path = \"ftp://gssc.esa.int/gnss/products/\"\n",
        "    # Validate product name\n",
        "    valid_products = {\n",
        "        \"SP3\": \"IGS0OPSRAP_{year}{doy:03d}0000_01D_15M_ORB.SP3.gz\",\n",
        "        \"CLK\": \"IGS0OPSRAP_{year}{doy:03d}0000_01D_05M_CLK.CLK.gz\",\n",
        "        \"ERP\": \"IGS0OPSRAP_{year}{doy:03d}0000_01D_01D_ERP.ERP.gz\"\n",
        "    }\n",
        "    if product_name not in valid_products:\n",
        "        raise ValueError(f\"Invalid product name: {product_name}. Valid options are {list(valid_products.keys())}\")\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Download the specified product\n",
        "    for doy in range(doy_i,doy_f + 1):\n",
        "        week = gps_week(doy, year)\n",
        "        product_path = f\"{week}/\" + valid_products[product_name].format(year=year, doy=doy)\n",
        "\n",
        "        try:\n",
        "            with closing(urllib.request.urlopen(path + product_path)) as r:\n",
        "                local_file = os.path.join(save_path, os.path.basename(product_path))\n",
        "                with open(local_file, 'wb') as f:\n",
        "                    shutil.copyfileobj(r, f)\n",
        "            print(f\"Downloaded {product_name} file for day {doy}: {local_file}\")\n",
        "        except URLError:\n",
        "            print(f\"{product_name} file for day {doy} is missing\")\n",
        "\n",
        "        print(f\"Completed downloads for day of year {doy}\")"
      ],
      "metadata": {
        "id": "qCu-ydncSK6L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example usage of igs_station_data function**"
      ],
      "metadata": {
        "id": "C1soUHO2fHUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage of igs_station_data function\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Parameters\n",
        "    station_name = \"IISC\"        # Station name (e.g., \"IISC\")\n",
        "    doy_i = 152                  # Start day of the year (DOY)\n",
        "    doy_f = 156                  # End day of the year (DOY)\n",
        "    year = 2023                  # Year of the data\n",
        "    country_name = \"IND\"         # Country code (e.g., \"IND\" for India)\n",
        "    save_path = r\"D:\\TA\\CE334\\test\"  # Directory to save the files (ensure it exists)\n",
        "\n",
        "    # Create the directory if it does not exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Call the function\n",
        "    ##IGS Station Data\n",
        "    igs_station_data(\n",
        "        station_name=station_name,\n",
        "        doy_i=doy_i,\n",
        "        doy_f=doy_f,\n",
        "        year=year,\n",
        "        country_name=country_name,\n",
        "        save_path=save_path\n",
        "    )\n",
        "    #Product\n",
        "    product_name = \"SP3\"  # Specify the product name here (e.g., \"SP3\", \"CLK\", \"ERP\")\n",
        "    download_igs_product(year, doy_i, doy_f, product_name,save_path)"
      ],
      "metadata": {
        "id": "EjR-NJtzSUdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9664e7e-5c2d-4876-e532-0e05ae551539"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation file for DOY 152 has been downloaded\n",
            "Navigation file for DOY 152 has been downloaded\n",
            "Observation file for DOY 153 has been downloaded\n",
            "Navigation file for DOY 153 has been downloaded\n",
            "Observation file for DOY 154 has been downloaded\n",
            "Navigation file for DOY 154 has been downloaded\n",
            "Observation file for DOY 155 has been downloaded\n",
            "Navigation file for DOY 155 has been downloaded\n",
            "Observation file for DOY 156 has been downloaded\n",
            "Navigation file for DOY 156 has been downloaded\n",
            "Downloaded SP3 file for day 152: D:\\TA\\CE334\\test/IGS0OPSRAP_20231520000_01D_15M_ORB.SP3.gz\n",
            "Completed downloads for day of year 152\n",
            "Downloaded SP3 file for day 153: D:\\TA\\CE334\\test/IGS0OPSRAP_20231530000_01D_15M_ORB.SP3.gz\n",
            "Completed downloads for day of year 153\n",
            "Downloaded SP3 file for day 154: D:\\TA\\CE334\\test/IGS0OPSRAP_20231540000_01D_15M_ORB.SP3.gz\n",
            "Completed downloads for day of year 154\n",
            "Downloaded SP3 file for day 155: D:\\TA\\CE334\\test/IGS0OPSRAP_20231550000_01D_15M_ORB.SP3.gz\n",
            "Completed downloads for day of year 155\n",
            "Downloaded SP3 file for day 156: D:\\TA\\CE334\\test/IGS0OPSRAP_20231560000_01D_15M_ORB.SP3.gz\n",
            "Completed downloads for day of year 156\n"
          ]
        }
      ]
    }
  ]
}